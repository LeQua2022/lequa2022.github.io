---
layout: default
permalink: /evaluation/
title: Evaluation
---

## Evaluation 

- **Formats of dataset and submissions**
  - 
- **Tools and baselines**
  - A number of baseline (and advanced) methods for learning to quantify are implemented in the [QuaPy](https://pypi.org/project/QuaPy/) Python-based, open-source library, which also contains implementations of standard evaluation measures and evaluation protocols. You are welcome to use (and/or contribute new software to) [QuaPy](https://pypi.org/project/QuaPy/) and its tools for participating in this lab.
- **Evaluation measures / scorer**
  - The performance of the predictors will be evaluated in terms of the AE (absolute error) and RAE (relative absolute error) measure; AE will be used for the final ranking. 
  - A scorer that reflects how the evaluation is carried out will be released to participants.
