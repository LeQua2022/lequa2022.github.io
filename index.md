---
layout: default
---

# LeQua 2022: Learning to Quantify

The aim of LeQua 2022 (the 1st edition of the CLEF “Learning to Quantify” lab) is to allow the comparative evaluation of methods for “learning to quantify” in textual datasets, i.e., methods for training predictors of the relative frequencies of the classes of interest in sets of unlabelled textual documents. These predictors (called “quantifiers”) will be required to issue predictions for several such sets, some of them characterized by class frequencies radically different from the ones of the training set. For a detailed description of this lab you are welcome to download the paper [Andrea Esuli, Alejandro Moreo, Fabrizio Sebastiani: LeQua@CLEF2022: Learning to Quantify. Proceedings of the 44th European Conference on Information Retrieval (ECIR 2022), Stavanger, NO. Forthcoming.](http://nmis.isti.cnr.it/sebastiani/LeQua2022.pdf).

## News!

* 1st Dec: The dataset (training and development sets) **is now public** and accessible via [Zenodo](https://www.doi.org/10.5281/zenodo.5734465)!
* 1st Dec: The `format checker`, the `evaluation script`, along with other useful functions and further guidelines, are public and accessible via [GitHub](https://github.com/HLT-ISTI/LeQua2022_scripts).
* The Google discussion group has been created! If you plan to participate (and we very much hope so), visit https://groups.google.com/g/lequa2022 and request to become a member now!
* 15 Nov: [Registrations](http://clef2022-labs-registration.dei.unipd.it/) are open! (until 22 Apr 2022)

## Useful links

If you are interested in research on learning to quantify, you might want to check the proceedings on the [1st International Workshop on Learning to Quantify (LQ 2021)](https://cikmlq2021.github.io/), which took place on November 1 and November 5, 2021.

For a survey of research on learning to quantify up to 2017, see [Pablo González, Alberto Castaño, Nitesh V. Chawla, Juan José del Coz: A Review on Quantification Learning. ACM Computing Surveys 50(5): 74:1-74:40 (2017)](https://dl.acm.org/doi/10.1145/3117807); for more recent work, check the forthcoming proceedings of [LQ 2021](https://cikmlq2021.github.io/).

Register you and your team for participating to LeQua 2022 (and other CLEF 2022 labs too) on the [CLEF 2022 Lab registration page](https://clef2022-labs-registration.dei.unipd.it/).

Follow us on Twitter: [@LeQua2022](https://twitter.com/LeQua2022)

![cropped-SoBigData-RI-768x257](https://user-images.githubusercontent.com/92160733/142188337-675041c8-29cf-4d32-a3bf-603fc8b7a787.png)

![ai4media-768x444](https://user-images.githubusercontent.com/92160733/142188325-90cc9258-a43e-47d6-ad68-a8fc2bb90526.png)

LeQua 2022 is supported by the SoBigData++ project, funded by the European Commission (Grant 871042) under the H2020 Programme INFRAIA-2019-1, and by the AI4Media project, funded by the European Commission (Grant 951911) under the H2020 Programme ICT-48-2020. The organizers' opinions do not necessarily reflect those of the European Commission.
